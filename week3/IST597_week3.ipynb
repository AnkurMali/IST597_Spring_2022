{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST597_week2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/IST597_week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7r1fJQniHj7"
      },
      "source": [
        "# Tutorial IST597 (Spring 2022):- Intro to Eager Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwZoGf85dnU"
      },
      "source": [
        "# Enabling Eager Execution \n",
        "In version 2.0 and above eager execution is set TRUE by default. For all other versions $<1.7$ (if working on server with outdated tf version) enable using tf.enable_eager_execution() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlnQG8hC-uCg"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# tf.enable_eager_execution() # Only use if TF < 2.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fq5Gb135Z5f"
      },
      "source": [
        "Check if eager execution is enabled or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS7er1hy-7yO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa110d53-02bc-4d96-dfc9-84a135e91a3b"
      },
      "source": [
        "tf.executing_eagerly()\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC6X5Y844_E-"
      },
      "source": [
        "# Executing tf Ops Eagerly \n",
        "More pythonic : Since by perfoming operations we can see the output directly.\n",
        "No Session or sess.run(operation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmwZJKlA_B15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf2c32d-f67c-476a-f55d-b7add9dc11af"
      },
      "source": [
        "x = [[2.]]\n",
        "m = tf.square(x)\n",
        "print(m)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGLoIPrQ6ZYT"
      },
      "source": [
        "Also can call `.numpy` to retrieve the results of the tensor as a numpy array (Useful for people who are familiar with pytorch or numpy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FGFGbZq6fRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4edc2f-04ce-4b0c-f851-faef372f20a3"
      },
      "source": [
        "m.numpy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Xlu7in6m22"
      },
      "source": [
        "compute an operation including two tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4tKJJ90_QMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a25141-f9c2-4dfb-981f-51214a491e77"
      },
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "\n",
        "b = tf.constant([[2, 1],\n",
        "                 [3, 4]])\n",
        "\n",
        "ab = tf.matmul(a, b)\n",
        "\n",
        "print('a * b = \\n', ab.numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a * b = \n",
            " [[ 8  9]\n",
            " [18 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5qlVJygETcb"
      },
      "source": [
        "# Constants and Variables [Try to understand the difference between two]\n",
        "\n",
        "\n",
        "*   `tf.constant`, creates a constant tensor populated with the values as argument. The values are immutable. \n",
        "*   `tf.Variable `, this method encapsultes a mutable tensor that can be changed later using assign. \n",
        "(From official tensorflow documentation.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayMVXFj1FZxz"
      },
      "source": [
        "Create a constant tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2KFQKSLFNlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b41e63-491b-4569-8454-a78d9bd18264"
      },
      "source": [
        "a = tf.constant([[2,3]])\n",
        "print(a)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn8uX4t5FtHp"
      },
      "source": [
        "As we discussed constant tensor is immutable so we cannot assign a new value to it. Let's see an example for this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrJqeZfgHU-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6125b75-9435-40d9-97ae-f5d3cf004355"
      },
      "source": [
        "try:\n",
        "  a.assign([[3,4]])\n",
        "except:\n",
        "  print('Exception raised trying to change immutable tensor ')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception raised trying to change immutable tensor \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrgbhCu8H3rm"
      },
      "source": [
        "On the other hand variables are mutable and can be assigned a new value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSMIotOQFw2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a771368e-6c2e-4c6f-c7a4-11a5964697eb"
      },
      "source": [
        "v = tf.Variable(5.)\n",
        "\n",
        "print('previous value v =', v.numpy())\n",
        "v.assign(2.)\n",
        "print('Current value v =', v.numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previous value v = 5.0\n",
            "Current value v = 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se0MFrEwMXWo"
      },
      "source": [
        "increment/decrement the value of a tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9M50PpdMzEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47972b78-9740-4b2c-823a-6fa94fc74858"
      },
      "source": [
        "v.assign(2.)\n",
        "print('value     : ', v.numpy())\n",
        "print('increment : ', tf.math.add(v, 1).numpy())\n",
        "print('decrement : ', tf.math.subtract(v, 1).numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value     :  2.0\n",
            "increment :  3.0\n",
            "decrement :  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLlbAcRLbizw",
        "outputId": "5b7f8fe7-5776-4f54-9d34-1da3fa63e10b"
      },
      "source": [
        "v2 = tf.Variable(15.)\n",
        "v2.assign(2.)\n",
        "print('value     : ', v2.numpy())\n",
        "print('increment : ', tf.compat.v1.assign_add(v2, 1).numpy())\n",
        "print('decrement : ', tf.compat.v1.assign_sub(v2, 1).numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value     :  2.0\n",
            "increment :  3.0\n",
            "decrement :  2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtGAYUUWI8bX"
      },
      "source": [
        "You can return many information from a tensor variable same as numpy, like name, type, shape and system device function is executed on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wQMtx3QJBSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960341e1-a2f3-4c1b-d17a-26d950bc4cc7"
      },
      "source": [
        "print('name  : ', v.name)\n",
        "print('type  : ', v.dtype)\n",
        "print('shape : ', v.shape)\n",
        "print('device: ', v.device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name  :  Variable:0\n",
            "type  :  <dtype: 'float32'>\n",
            "shape :  ()\n",
            "device:  /job:localhost/replica:0/task:0/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5irSm-yDN0nV"
      },
      "source": [
        "# Gradient Evaluation[Imp Concept]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y36ig_TVAAoM"
      },
      "source": [
        "Gradient evaluation is important in evaluating our deep learning model. It based on function optimization and will provide true gradients for your model. You can use `tf.GradientTape()` method to record the gradient of any valid arbitrary function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdZmXyAi_3M3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5dd71c-84b0-4ac8-e486-a6bf65ce52e8"
      },
      "source": [
        "w = tf.Variable(2.0)\n",
        "\n",
        "#watch the gradient of the loss operation\n",
        "with tf.GradientTape() as tape:\n",
        "  loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(f'The gradient of w^2 at {w.numpy()} is {grad.numpy()}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient of w^2 at 2.0 is 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEMEMfV8Pwvt"
      },
      "source": [
        "We can also compute the gradient of the function using tape. In this example we evaluate the gradient of the sigmoid function \n",
        "\n",
        "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
        "\n",
        "Note that \n",
        "\n",
        "$$f'(x) = \\frac{e^{-x}}{(1+e^{-x})^2} = f(x)(1-f(x)) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrw-DuoWP0A6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995c31f8-df03-4c4c-c270-8f155fc9a761"
      },
      "source": [
        "w = tf.Variable(2.0)\n",
        "z = 1/(1 + tf.exp(-2.0))\n",
        "print(z) # Print value of your function\n",
        "@tf.function\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + tf.exp(-x))\n",
        "print(tf.math.sigmoid(2.0)) # Check with inbuilt function\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  sigmoid_value = sigmoid(w)\n",
        "grad_sigmoid = tape.gradient(sigmoid_value, w)\n",
        "print('The gradient of the sigmoid function at 2.0 is ', grad_sigmoid.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.880797, shape=(), dtype=float32)\n",
            "tf.Tensor(0.880797, shape=(), dtype=float32)\n",
            "The gradient of the sigmoid function at 2.0 is  0.104993574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jew_BsZaYeVz"
      },
      "source": [
        "You can also compute higher order derivatives by nesting a gradient functions or gradient tape. For instance, \n",
        "\n",
        "$$f(x) = \\log(x) , f'(x) = \\frac{1}{x}, f''(x) = \\frac{-1}{x^2}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoFFIr_AXUnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f573b3-536b-4685-fd24-9ed1d42f9400"
      },
      "source": [
        "x = tf.Variable(1.0)\n",
        "@tf.function\n",
        "def log(x):\n",
        "  return tf.math.log(x)\n",
        "with tf.GradientTape(persistent=True) as tape3:\n",
        "  with tf.GradientTape(persistent=True) as tape2:\n",
        "    with tf.GradientTape(persistent=True) as tape1:\n",
        "      dx = log(x)\n",
        "    dx_log = tape1.gradient(dx, x)\n",
        "  dx2_log = tape2.gradient(dx_log, x )\n",
        "dx3_log = tape3.gradient(dx2_log, x)\n",
        "\n",
        "print('The first  derivative of log at x = 1 is ', dx_log.numpy())\n",
        "print('The second derivative of log at x = 1 is ', dx2_log.numpy())\n",
        "print('The third  derivative of log at x = 1 is ', dx3_log.numpy())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first  derivative of log at x = 1 is  1.0\n",
            "The second derivative of log at x = 1 is  -1.0\n",
            "The third  derivative of log at x = 1 is  2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBVnUE6DRDFw"
      },
      "source": [
        "# Custom Gradients\n",
        "\n",
        "Some times the gradient is not what we want espeically if there is a problem in numerical instabilitiy. Consider the following function and its gradient \n",
        "\n",
        "$$f(x) = \\log(1+e^x)$$\n",
        "\n",
        "The gradient is \n",
        "\n",
        "$$f'(x) = \\frac{e^x}{1+e^x}$$\n",
        "\n",
        "Note that at big values of $x$ the gradient value will blow up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "autHEivlRp9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38df6f4-93da-4561-999d-d09c30dc8fad"
      },
      "source": [
        "x = tf.Variable(1.0)\n",
        "x1 = tf.Variable(100.0)\n",
        "@tf.function\n",
        "def logexp(x):\n",
        "  return tf.math.log(1 + tf.exp(x))\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  grad_value = logexp(x)\n",
        "  grad_value2 = logexp(x1)\n",
        "grad_logexp = tape.gradient(grad_value, x)\n",
        "grad_logexp2 = tape.gradient(grad_value2, x1)\n",
        "print('The gradient at x = 0  is ', grad_logexp.numpy())  \n",
        "\n",
        "print('The gradient at x1 = 100 is ', grad_logexp2.numpy()) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient at x = 0  is  0.7310586\n",
            "The gradient at x1 = 100 is  nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19m7XawUR1a"
      },
      "source": [
        " We can revaluate the gradient by overriding the gradient of the function. We can recompute the gradient as \n",
        "\n",
        "$$f(x) =  \\frac{1+e^x -e^x }{1+e^x} = 1 - \\frac{1}{1 + e^{x}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmPT2S6XUJ8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268f04d0-56a5-4289-868d-a96bef72a6b1"
      },
      "source": [
        "x = tf.Variable(1.0)\n",
        "x1 = tf.Variable(100.0)\n",
        "@tf.custom_gradient\n",
        "def logexp_stable(x):\n",
        "  e = tf.exp(x)\n",
        "  #dy is optional, allows computation of vector jacobian products for vectors other than the vector of ones.\n",
        "  def grad(dy):\n",
        "    return dy * (1 - 1 / (1 + e))\n",
        "  return tf.math.log(1 + e), grad\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  grad_value = logexp_stable(x)\n",
        "  grad_value2 = logexp_stable(x1)\n",
        "grad_logexp_stable = tape.gradient(grad_value, x)\n",
        "grad_logexp_stable1 = tape.gradient(grad_value2, x1)\n",
        "\n",
        "print('The gradient at x = 1 is ', grad_logexp_stable.numpy()) \n",
        "print('The gradient at x1 = 100 is ', grad_logexp_stable1.numpy()) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient at x = 1 is  0.7310586\n",
            "The gradient at x1 = 100 is  1.0\n"
          ]
        }
      ]
    }
  ]
}